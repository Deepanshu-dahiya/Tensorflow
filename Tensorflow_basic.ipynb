{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensor_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXhcj-R8Cicg"
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pci_JMhIC2SO"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXw8gLw_C2jV",
        "outputId": "4975b7db-29de-45b9-851b-4ce69e0d8183"
      },
      "source": [
        "print (tf.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHuXGCTRF8B_"
      },
      "source": [
        "mnist=keras.datasets.fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEK8UcDQF8H3",
        "outputId": "bd0e7350-e5bc-453e-8da7-7d5dd042afd5"
      },
      "source": [
        "type(mnist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "module"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gguuHHSxF8La"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGhGStM9F8Oc"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqlIdN1uF8Su"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ddw8jsxF8UM",
        "outputId": "592a1e9b-620e-40cf-9fc8-9596faa4295e"
      },
      "source": [
        "np.max(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWj9J6ASHPT5",
        "outputId": "a2b21c67-43ed-4f6f-afe9-c427c5b0e02b"
      },
      "source": [
        "np.mean(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72.94035223214286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_W2zwPOHPWe",
        "outputId": "6255543c-ba5f-42f4-ea2a-ee5d67605519"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDcfo4DGHPZP"
      },
      "source": [
        "class_names1=['top','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Bpv1RKHPhY"
      },
      "source": [
        "####Data Exploration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBl6G6MlHPk4",
        "outputId": "ad878aa7-4b67-45d1-dd16-7e59e54cc7a0"
      },
      "source": [
        "x_train.shape,x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "-dPXFcNpHPsI",
        "outputId": "b3caf1e7-4315-4e62-8d73-537d4b16a2d3"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(x_train[0])\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f9d3cdb56d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iF4NnFbJNM5",
        "outputId": "7583d399-5ba1-48b9-fab6-8ed1ebe5fc49"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIoA-pyaJNQE"
      },
      "source": [
        "x_train=x_train/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIuL1f1rJNSb"
      },
      "source": [
        "x_test=x_test/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "J9-OCIq9KBK0",
        "outputId": "746c5702-f3f0-47d5-b3f8-4a71c73f24f8"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(x_train[0])\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f9d3cd557f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G36ShjBKBNp"
      },
      "source": [
        "#Building the model TF.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po1G9MGjKBQF"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xH1P5UIKBTD"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(128,activation=\"relu\"))\n",
        "\n",
        "model.add(Dense(10,activation=\"sigmoid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH6osfbtKBVC",
        "outputId": "fb6f2831-bc8f-48de-9193-527cc15eb1de"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_8 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zEiT5Q7KBYG"
      },
      "source": [
        "#loss Funation\n",
        "#optimization\n",
        "#metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJw1q4egKBbR"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-NpTLrPKBgG",
        "outputId": "60c397fa-f82d-4eae-c7e7-b97e2b90cbe1"
      },
      "source": [
        "model.fit(x_train,y_train,epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6166 - accuracy: 0.7864\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3855 - accuracy: 0.8612\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3330 - accuracy: 0.8794\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3077 - accuracy: 0.8857\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2930 - accuracy: 0.8914\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2818 - accuracy: 0.8954\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2674 - accuracy: 0.9007\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2567 - accuracy: 0.9056\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2479 - accuracy: 0.9072\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2360 - accuracy: 0.9132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9d3cccb320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptj2S0o8tOdX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PT9GmUCOCOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44456f51-1f30-4def-f395-51add9f74d3e"
      },
      "source": [
        "test_loss,test_acc = model.evaluate(x_test,y_test)\n",
        "print(test_acc)\n",
        "print(test_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8846\n",
            "0.8845999836921692\n",
            "0.3219989836215973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWOgfc0UOCUY"
      },
      "source": [
        "from sklearn.metrics import  accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k8phd6SOCWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6dcc7f-b6e9-446e-a282-8c8d7d3f6190"
      },
      "source": [
        "y_pred=model.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9JL-BSFQ1bG",
        "outputId": "00bb8e21-5310-474e-b55a-8abc9c97572e"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, ..., 8, 1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKDrCugsKBjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329e258e-8638-4735-8f5d-075fc288ae86"
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYppOdPVQgQC"
      },
      "source": [
        "pred=model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w8knOJjQgV6",
        "outputId": "89e78bf0-a857-4aaf-aabc-15b028235531"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.0008154e-05, 3.5784674e-06, 1.9583081e-06, ..., 4.7838497e-01,\n",
              "        1.7264587e-05, 9.9661696e-01],\n",
              "       [6.0692114e-01, 6.1625949e-09, 9.9991214e-01, ..., 6.4838803e-13,\n",
              "        3.1229320e-07, 9.1829264e-08],\n",
              "       [5.6361914e-02, 1.0000000e+00, 3.9753318e-04, ..., 5.0805727e-14,\n",
              "        1.1959680e-06, 3.4958103e-09],\n",
              "       ...,\n",
              "       [2.3721129e-02, 9.4406914e-08, 8.9129806e-04, ..., 4.6992736e-06,\n",
              "        9.9430239e-01, 4.9773149e-08],\n",
              "       [6.6193938e-04, 9.9999714e-01, 3.4335256e-04, ..., 8.9400438e-11,\n",
              "        3.6698832e-05, 7.6531691e-08],\n",
              "       [1.0346770e-03, 3.1596537e-07, 1.0555498e-04, ..., 2.1633974e-01,\n",
              "        1.2072146e-02, 3.6486983e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UfvJQ5kQga7",
        "outputId": "9559e410-49df-4d19-b6e9-5b74184d21d1"
      },
      "source": [
        "pred[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.0008154e-05, 3.5784674e-06, 1.9583081e-06, 1.5990730e-06,\n",
              "       8.5161701e-06, 1.3264522e-01, 5.3162395e-05, 4.7838497e-01,\n",
              "       1.7264587e-05, 9.9661696e-01], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krLD7IZJQ_CM",
        "outputId": "fb5639eb-fac1-478f-b2f8-620342ff2132"
      },
      "source": [
        "np.argmax(pred[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-dCfFK-Q_I5",
        "outputId": "af9dc93f-4bd2-4d2c-ce21-d6d7aa802b96"
      },
      "source": [
        "np.argmax(pred[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYb5KyRkQ_L0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz8OXCB3ojKe"
      },
      "source": [
        "Plot Learning Curves and Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNh8Aq3tQ_OG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68c5528b-e843-4470-c568-a296d59f746e"
      },
      "source": [
        "help(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on Sequential in module tensorflow.python.keras.engine.sequential object:\n",
            "\n",
            "class Sequential(tensorflow.python.keras.engine.functional.Functional)\n",
            " |  `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
            " |  \n",
            " |  `Sequential` provides training and inference features on this model.\n",
            " |  \n",
            " |  Examples:\n",
            " |  \n",
            " |  >>> # Optionally, the first layer can receive an `input_shape` argument:\n",
            " |  >>> model = tf.keras.Sequential()\n",
            " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
            " |  >>> # Afterwards, we do automatic shape inference:\n",
            " |  >>> model.add(tf.keras.layers.Dense(4))\n",
            " |  \n",
            " |  >>> # This is identical to the following:\n",
            " |  >>> model = tf.keras.Sequential()\n",
            " |  >>> model.add(tf.keras.Input(shape=(16,)))\n",
            " |  >>> model.add(tf.keras.layers.Dense(8))\n",
            " |  \n",
            " |  >>> # Note that you can also omit the `input_shape` argument.\n",
            " |  >>> # In that case the model doesn't have any weights until the first call\n",
            " |  >>> # to a training/evaluation method (since it isn't yet built):\n",
            " |  >>> model = tf.keras.Sequential()\n",
            " |  >>> model.add(tf.keras.layers.Dense(8))\n",
            " |  >>> model.add(tf.keras.layers.Dense(4))\n",
            " |  >>> # model.weights not created yet\n",
            " |  \n",
            " |  >>> # Whereas if you specify the input shape, the model gets built\n",
            " |  >>> # continuously as you are adding layers:\n",
            " |  >>> model = tf.keras.Sequential()\n",
            " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
            " |  >>> model.add(tf.keras.layers.Dense(4))\n",
            " |  >>> len(model.weights)\n",
            " |  4\n",
            " |  \n",
            " |  >>> # When using the delayed-build pattern (no input shape specified), you can\n",
            " |  >>> # choose to manually build your model by calling\n",
            " |  >>> # `build(batch_input_shape)`:\n",
            " |  >>> model = tf.keras.Sequential()\n",
            " |  >>> model.add(tf.keras.layers.Dense(8))\n",
            " |  >>> model.add(tf.keras.layers.Dense(4))\n",
            " |  >>> model.build((None, 16))\n",
            " |  >>> len(model.weights)\n",
            " |  4\n",
            " |  \n",
            " |  ```python\n",
            " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
            " |  # the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
            " |  # or the first time you call the model on some input data.\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(1))\n",
            " |  model.compile(optimizer='sgd', loss='mse')\n",
            " |  # This builds the model for the first time:\n",
            " |  model.fit(x, y, batch_size=32, epochs=10)\n",
            " |  ```\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Sequential\n",
            " |      tensorflow.python.keras.engine.functional.Functional\n",
            " |      tensorflow.python.keras.engine.training.Model\n",
            " |      tensorflow.python.keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
            " |      tensorflow.python.training.tracking.base.Trackable\n",
            " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
            " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, layers=None, name=None)\n",
            " |      Creates a `Sequential` model instance.\n",
            " |      \n",
            " |      Args:\n",
            " |        layers: Optional list of layers to add to the model.\n",
            " |        name: Optional name for the model.\n",
            " |  \n",
            " |  add(self, layer)\n",
            " |      Adds a layer instance on top of the layer stack.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          layer: layer instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          TypeError: If `layer` is not a layer instance.\n",
            " |          ValueError: In case the `layer` argument does not\n",
            " |              know its input shape.\n",
            " |          ValueError: In case the `layer` argument has\n",
            " |              multiple output tensors, or is already connected\n",
            " |              somewhere else (forbidden in `Sequential` models).\n",
            " |  \n",
            " |  build(self, input_shape=None)\n",
            " |      Builds the model based on input shapes received.\n",
            " |      \n",
            " |      This is to be used for subclassed models, which do not know at instantiation\n",
            " |      time what their inputs look like.\n",
            " |      \n",
            " |      This method only exists for users who want to call `model.build()` in a\n",
            " |      standalone way (as a substitute for calling the model on real data to\n",
            " |      build it). It will never be called by the framework (and thus it will\n",
            " |      never throw unexpected errors in an unrelated workflow).\n",
            " |      \n",
            " |      Args:\n",
            " |       input_shape: Single tuple, TensorShape, or list/dict of shapes, where\n",
            " |           shapes are tuples, integers, or TensorShapes.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError:\n",
            " |          1. In case of invalid user-provided data (not of type tuple,\n",
            " |             list, TensorShape, or dict).\n",
            " |          2. If the model requires call arguments that are agnostic\n",
            " |             to the input shapes (positional or kwarg in call signature).\n",
            " |          3. If not all layers were properly built.\n",
            " |          4. If float type inputs are not supported within the layers.\n",
            " |      \n",
            " |        In each of these cases, the user should build their model by calling it\n",
            " |        on real tensor data.\n",
            " |  \n",
            " |  call(self, inputs, training=None, mask=None)\n",
            " |      Calls the model on new inputs.\n",
            " |      \n",
            " |      In this case `call` just reapplies\n",
            " |      all ops in the graph to the new inputs\n",
            " |      (e.g. build a new computational graph from the provided inputs).\n",
            " |      \n",
            " |      Arguments:\n",
            " |          inputs: A tensor or list of tensors.\n",
            " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
            " |            the `Network` in training mode or inference mode.\n",
            " |          mask: A mask or list of masks. A mask can be\n",
            " |              either a tensor or None (no mask).\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor if there is a single output, or\n",
            " |          a list of tensors if there are more than one outputs.\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      If the layer has not been built, this method will call `build` on the\n",
            " |      layer. This assumes that the layer will later be used with inputs that\n",
            " |      match the input shape provided here.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          input_shape: Shape tuple (tuple of integers)\n",
            " |              or list of shape tuples (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An input shape tuple.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the layer.\n",
            " |      \n",
            " |      A layer config is a Python dictionary (serializable)\n",
            " |      containing the configuration of a layer.\n",
            " |      The same layer can be reinstantiated later\n",
            " |      (without its trained weights) from this configuration.\n",
            " |      \n",
            " |      The config of a layer does not include connectivity\n",
            " |      information, nor the layer class name. These are handled\n",
            " |      by `Network` (one layer of abstraction above).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary.\n",
            " |  \n",
            " |  pop(self)\n",
            " |      Removes the last layer in the model.\n",
            " |      \n",
            " |      Raises:\n",
            " |          TypeError: if there are no layers in the model.\n",
            " |  \n",
            " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
            " |      Generate class predictions for the input samples.\n",
            " |      \n",
            " |      The input samples are processed batch by batch.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: input data, as a Numpy array or list of Numpy arrays\n",
            " |              (if the model has multiple inputs).\n",
            " |          batch_size: integer.\n",
            " |          verbose: verbosity mode, 0 or 1.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A numpy array of class predictions.\n",
            " |  \n",
            " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
            " |      Generates class probability predictions for the input samples.\n",
            " |      \n",
            " |      The input samples are processed batch by batch.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: input data, as a Numpy array or list of Numpy arrays\n",
            " |              (if the model has multiple inputs).\n",
            " |          batch_size: integer.\n",
            " |          verbose: verbosity mode, 0 or 1.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A Numpy array of probability predictions.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  from_config(config, custom_objects=None) from builtins.type\n",
            " |      Instantiates a Model from its config (output of `get_config()`).\n",
            " |      \n",
            " |      Arguments:\n",
            " |          config: Model config dictionary.\n",
            " |          custom_objects: Optional dictionary mapping names\n",
            " |              (strings) to custom classes or functions to be\n",
            " |              considered during deserialization.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A model instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of improperly formatted config dict.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  input_spec\n",
            " |      `InputSpec` instance(s) describing the input format for this layer.\n",
            " |      \n",
            " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
            " |      the layer to run input compatibility checks when it is called.\n",
            " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
            " |      of rank 4. As such, you can set, in `__init__()`:\n",
            " |      \n",
            " |      ```python\n",
            " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            " |      ```\n",
            " |      \n",
            " |      Now, if you try to call the layer on an input that isn't rank 4\n",
            " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
            " |      error:\n",
            " |      \n",
            " |      ```\n",
            " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            " |      ```\n",
            " |      \n",
            " |      Input checks that can be specified via `input_spec` include:\n",
            " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            " |      - Shape\n",
            " |      - Rank (ndim)\n",
            " |      - Dtype\n",
            " |      \n",
            " |      For more information, see `tf.keras.layers.InputSpec`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            " |  \n",
            " |  layers\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.keras.engine.functional.Functional:\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs)\n",
            " |      Configures the model for training.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
            " |            `tf.keras.optimizers`.\n",
            " |          loss: String (name of objective function), objective function or\n",
            " |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
            " |            function is any callable with the signature `loss = fn(y_true,\n",
            " |            y_pred)`, where y_true = ground truth values with shape =\n",
            " |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
            " |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
            " |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
            " |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
            " |            used and reduction is set to NONE, return value has the shape\n",
            " |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
            " |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
            " |            use a different loss on each output by passing a dictionary or a list\n",
            " |            of losses. The loss value that will be minimized by the model will\n",
            " |            then be the sum of all individual losses.\n",
            " |          metrics: List of metrics to be evaluated by the model during training\n",
            " |            and testing. Each of this can be a string (name of a built-in\n",
            " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
            " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
            " |            function is any callable with the signature `result = fn(y_true,\n",
            " |            y_pred)`. To specify different metrics for different outputs of a\n",
            " |            multi-output model, you could also pass a dictionary, such as\n",
            " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
            " |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
            " |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
            " |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
            " |                strings 'accuracy' or 'acc', we convert this to one of\n",
            " |                `tf.keras.metrics.BinaryAccuracy`,\n",
            " |                `tf.keras.metrics.CategoricalAccuracy`,\n",
            " |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
            " |                function used and the model output shape. We do a similar\n",
            " |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
            " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
            " |            (Python floats) to weight the loss contributions of different model\n",
            " |            outputs. The loss value that will be minimized by the model will then\n",
            " |            be the *weighted sum* of all individual losses, weighted by the\n",
            " |            `loss_weights` coefficients.\n",
            " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
            " |                outputs. If a dict, it is expected to map output names (strings)\n",
            " |                to scalar coefficients.\n",
            " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
            " |            sample_weight or class_weight during training and testing.\n",
            " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
            " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
            " |            this as `None` unless your `Model` cannot be run inside a\n",
            " |            `tf.function`.\n",
            " |          steps_per_execution: Int. Defaults to 1. The number of batches to\n",
            " |            run during each `tf.function` call. Running multiple batches\n",
            " |            inside a single `tf.function` call can greatly improve performance\n",
            " |            on TPUs or small models with a large Python overhead.\n",
            " |            At most, one full epoch will be run each\n",
            " |            execution. If a number larger than the size of the epoch is passed,\n",
            " |            the execution will be truncated to the size of the epoch.\n",
            " |            Note that if `steps_per_execution` is set to `N`,\n",
            " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
            " |            will only be called every `N` batches\n",
            " |            (i.e. before/after each `tf.function` execution).\n",
            " |          **kwargs: Arguments supported for backwards compatibility only.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of invalid arguments for\n",
            " |              `optimizer`, `loss` or `metrics`.\n",
            " |  \n",
            " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
            " |      Returns the loss value & metrics values for the model in test mode.\n",
            " |      \n",
            " |      Computation is done in batches (see the `batch_size` arg.)\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            " |              or `(inputs, targets, sample_weights)`.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            " |            for iterator-like inputs` section of `Model.fit`.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
            " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
            " |            should not be specified (since targets will be obtained from the\n",
            " |            iterator/dataset).\n",
            " |          batch_size: Integer or `None`. Number of samples per batch of\n",
            " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
            " |            specify the `batch_size` if your data is in the form of a dataset,\n",
            " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
            " |            batches).\n",
            " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
            " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
            " |            used for weighting the loss function. You can either pass a flat (1D)\n",
            " |            Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples), or in the case of\n",
            " |                temporal data, you can pass a 2D array with shape `(samples,\n",
            " |                sequence_length)`, to apply a different weight to every timestep\n",
            " |                of every sample. This argument is not supported when `x` is a\n",
            " |                dataset, instead pass sample weights as the third element of `x`.\n",
            " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            " |            before declaring the evaluation round finished. Ignored with the\n",
            " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
            " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
            " |            argument is not supported with array inputs.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            " |            callbacks to apply during evaluation. See\n",
            " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |            input only. Maximum size for the generator queue. If unspecified,\n",
            " |            `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |            only. Maximum number of processes to spin up when using process-based\n",
            " |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
            " |            execute the generator on the main thread.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |            threading. If unspecified, `use_multiprocessing` will default to\n",
            " |            `False`. Note that because this implementation relies on\n",
            " |            multiprocessing, you should not pass non-picklable arguments to the\n",
            " |            generator as they can't be passed easily to children processes.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
            " |          ValueError: in case of invalid arguments.\n",
            " |  \n",
            " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Evaluates the model on a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            " |              or `(inputs, targets, sample_weights)`.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given below.\n",
            " |          y: Target data. Like the input data `x`,\n",
            " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
            " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
            " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
            " |            or `keras.utils.Sequence` instance, `y` should\n",
            " |            not be specified (since targets will be obtained from `x`).\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per gradient update.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          epochs: Integer. Number of epochs to train the model.\n",
            " |              An epoch is an iteration over the entire `x` and `y`\n",
            " |              data provided.\n",
            " |              Note that in conjunction with `initial_epoch`,\n",
            " |              `epochs` is to be understood as \"final epoch\".\n",
            " |              The model is not trained for a number of iterations\n",
            " |              given by `epochs`, but merely until the epoch\n",
            " |              of index `epochs` is reached.\n",
            " |          verbose: 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
            " |              Note that the progress bar is not particularly useful when\n",
            " |              logged to a file, so verbose=2 is recommended when not running\n",
            " |              interactively (eg, in a production environment).\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during training.\n",
            " |              See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
            " |              and `tf.keras.callbacks.History` callbacks are created automatically\n",
            " |              and need not be passed into `model.fit`.\n",
            " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
            " |              `verbose` argument to `model.fit`.\n",
            " |          validation_split: Float between 0 and 1.\n",
            " |              Fraction of the training data to be used as validation data.\n",
            " |              The model will set apart this fraction of the training data,\n",
            " |              will not train on it, and will evaluate\n",
            " |              the loss and any model metrics\n",
            " |              on this data at the end of each epoch.\n",
            " |              The validation data is selected from the last samples\n",
            " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
            " |              not supported when `x` is a dataset, generator or\n",
            " |             `keras.utils.Sequence` instance.\n",
            " |          validation_data: Data on which to evaluate\n",
            " |              the loss and any model metrics at the end of each epoch.\n",
            " |              The model will not be trained on this data. Thus, note the fact\n",
            " |              that the validation loss of data provided using `validation_split`\n",
            " |              or `validation_data` is not affected by regularization layers like\n",
            " |              noise and dropout.\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |              `validation_data` could be:\n",
            " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
            " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
            " |                - dataset\n",
            " |              For the first two cases, `batch_size` must be provided.\n",
            " |              For the last case, `validation_steps` could be provided.\n",
            " |              Note that `validation_data` does not support all the data types that\n",
            " |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
            " |          shuffle: Boolean (whether to shuffle the training data\n",
            " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
            " |              when `x` is a generator. 'batch' is a special option for dealing\n",
            " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
            " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |              to a weight (float) value, used for weighting the loss function\n",
            " |              (during training only).\n",
            " |              This can be useful to tell the model to\n",
            " |              \"pay more attention\" to samples from\n",
            " |              an under-represented class.\n",
            " |          sample_weight: Optional Numpy array of weights for\n",
            " |              the training samples, used for weighting the loss function\n",
            " |              (during training only). You can either pass a flat (1D)\n",
            " |              Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples),\n",
            " |              or in the case of temporal data,\n",
            " |              you can pass a 2D array with shape\n",
            " |              `(samples, sequence_length)`,\n",
            " |              to apply a different weight to every timestep of every sample. This\n",
            " |              argument is not supported when `x` is a dataset, generator, or\n",
            " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
            " |              as the third element of `x`.\n",
            " |          initial_epoch: Integer.\n",
            " |              Epoch at which to start training\n",
            " |              (useful for resuming a previous training run).\n",
            " |          steps_per_epoch: Integer or `None`.\n",
            " |              Total number of steps (batches of samples)\n",
            " |              before declaring one epoch finished and starting the\n",
            " |              next epoch. When training with input tensors such as\n",
            " |              TensorFlow data tensors, the default `None` is equal to\n",
            " |              the number of samples in your dataset divided by\n",
            " |              the batch size, or 1 if that cannot be determined. If x is a\n",
            " |              `tf.data` dataset, and 'steps_per_epoch'\n",
            " |              is None, the epoch will run until the input dataset is exhausted.\n",
            " |              When passing an infinitely repeating dataset, you must specify the\n",
            " |              `steps_per_epoch` argument. This argument is not supported with\n",
            " |              array inputs.\n",
            " |          validation_steps: Only relevant if `validation_data` is provided and\n",
            " |              is a `tf.data` dataset. Total number of steps (batches of\n",
            " |              samples) to draw before stopping when performing validation\n",
            " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
            " |              will run until the `validation_data` dataset is exhausted. In the\n",
            " |              case of an infinitely repeated dataset, it will run into an\n",
            " |              infinite loop. If 'validation_steps' is specified and only part of\n",
            " |              the dataset will be consumed, the evaluation will start from the\n",
            " |              beginning of the dataset at each epoch. This ensures that the same\n",
            " |              validation samples are used every time.\n",
            " |          validation_batch_size: Integer or `None`.\n",
            " |              Number of samples per validation batch.\n",
            " |              If unspecified, will default to `batch_size`.\n",
            " |              Do not specify the `validation_batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          validation_freq: Only relevant if validation data is provided. Integer\n",
            " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
            " |              If an integer, specifies how many training epochs to run before a\n",
            " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
            " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
            " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
            " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |              input only. Maximum size for the generator queue.\n",
            " |              If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up\n",
            " |              when using process-based threading. If unspecified, `workers`\n",
            " |              will default to 1. If 0, will execute the generator on the main\n",
            " |              thread.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children processes.\n",
            " |      \n",
            " |      Unpacking behavior for iterator-like inputs:\n",
            " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
            " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
            " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
            " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
            " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
            " |        second and third elements will be used for y and sample_weight\n",
            " |        respectively. Any other type provided will be wrapped in a length one\n",
            " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
            " |        should still adhere to the top-level tuple structure.\n",
            " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
            " |        features, targets, and weights from the keys of a single dict.\n",
            " |          A notable unsupported data type is the namedtuple. The reason is that\n",
            " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
            " |        datatype (dict). So given a namedtuple of the form:\n",
            " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
            " |        it is ambiguous whether to reverse the order of the elements when\n",
            " |        interpreting the value. Even worse is a tuple of the form:\n",
            " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
            " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
            " |        and sample_weight or passed through as a single element to `x`. As a\n",
            " |        result the data processing code will simply raise a ValueError if it\n",
            " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `History` object. Its `History.history` attribute is\n",
            " |          a record of training loss values and metrics values\n",
            " |          at successive epochs, as well as validation loss values\n",
            " |          and validation metrics values (if applicable).\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: 1. If the model was never compiled or,\n",
            " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
            " |      \n",
            " |          ValueError: In case of mismatch between the provided input data\n",
            " |              and what the model expects or when the input data is empty.\n",
            " |  \n",
            " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
            " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
            " |        this endpoint.\n",
            " |  \n",
            " |  get_layer(self, name=None, index=None)\n",
            " |      Retrieves a layer based on either its name (unique) or index.\n",
            " |      \n",
            " |      If `name` and `index` are both provided, `index` will take precedence.\n",
            " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            " |      \n",
            " |      Arguments:\n",
            " |          name: String, name of layer.\n",
            " |          index: Integer, index of layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of invalid layer name or index.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Retrieves the weights of the model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A flat list of Numpy arrays.\n",
            " |  \n",
            " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
            " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
            " |      \n",
            " |      If `by_name` is False weights are loaded based on the network's\n",
            " |      topology. This means the architecture should be the same as when the weights\n",
            " |      were saved.  Note that layers that don't have weights are not taken into\n",
            " |      account in the topological ordering, so adding or removing layers is fine as\n",
            " |      long as they don't have weights.\n",
            " |      \n",
            " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
            " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
            " |      some of the layers have changed.\n",
            " |      \n",
            " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
            " |      from the TensorFlow format. Note that topological loading differs slightly\n",
            " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
            " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
            " |      TensorFlow format loads based on the object-local names of attributes to\n",
            " |      which layers are assigned in the `Model`'s constructor.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          filepath: String, path to the weights file to load. For weight files in\n",
            " |              TensorFlow format, this is the file prefix (the same as was passed\n",
            " |              to `save_weights`).\n",
            " |          by_name: Boolean, whether to load weights by name or by topological\n",
            " |              order. Only topological loading is supported for weight files in\n",
            " |              TensorFlow format.\n",
            " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
            " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
            " |              the weight (only valid when `by_name=True`).\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for loading weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          When loading a weight file in TensorFlow format, returns the same status\n",
            " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
            " |          ops are run automatically as soon as the network is built (on first call\n",
            " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
            " |          already built).\n",
            " |      \n",
            " |          When loading weights in HDF5 format, returns `None`.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
            " |              format.\n",
            " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
            " |            `False`.\n",
            " |  \n",
            " |  make_predict_function(self)\n",
            " |      Creates a function that executes one step of inference.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.predict_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.predict` or\n",
            " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
            " |  \n",
            " |  make_test_function(self)\n",
            " |      Creates a function that executes one step of evaluation.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.test_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.evaluate` or\n",
            " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
            " |  \n",
            " |  make_train_function(self)\n",
            " |      Creates a function that executes one step of training.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
            " |      logic to `Model.train_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.fit` or\n",
            " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Generates output predictions for the input samples.\n",
            " |      \n",
            " |      Computation is done in batches. This method is designed for performance in\n",
            " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
            " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
            " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
            " |      inference. Also, note the fact that test loss is not affected by\n",
            " |      regularization layers like noise and dropout.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input samples. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A `tf.data` dataset.\n",
            " |            - A generator or `keras.utils.Sequence` instance.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            " |            for iterator-like inputs` section of `Model.fit`.\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per batch.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          verbose: Verbosity mode, 0 or 1.\n",
            " |          steps: Total number of steps (batches of samples)\n",
            " |              before declaring the prediction round finished.\n",
            " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
            " |              dataset and `steps` is None, `predict` will\n",
            " |              run until the input dataset is exhausted.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during prediction.\n",
            " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |              input only. Maximum size for the generator queue.\n",
            " |              If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up when using\n",
            " |              process-based threading. If unspecified, `workers` will default\n",
            " |              to 1. If 0, will execute the generator on the main thread.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children processes.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
            " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
            " |      three methods.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
            " |          ValueError: In case of mismatch between the provided\n",
            " |              input data and the model's expectations,\n",
            " |              or in case a stateful model receives a number of samples\n",
            " |              that is not a multiple of the batch size.\n",
            " |  \n",
            " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Generates predictions for the input samples from a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.predict` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  predict_on_batch(self, x)\n",
            " |      Returns predictions for a single batch of samples.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
            " |          ValueError: In case of mismatch between given number of inputs and\n",
            " |            expectations of the model.\n",
            " |  \n",
            " |  predict_step(self, data)\n",
            " |      The logic for one inference step.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.make_predict_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of inference.\n",
            " |      This typically includes the forward pass.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_predict_function`, which can also be overridden.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of one inference step, typically the output of calling the\n",
            " |        `Model` on data.\n",
            " |  \n",
            " |  reset_metrics(self)\n",
            " |      Resets the state of all the metrics in the model.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> _ = model.fit(x, y, verbose=0)\n",
            " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
            " |      \n",
            " |      >>> model.reset_metrics()\n",
            " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
            " |  \n",
            " |  reset_states(self)\n",
            " |  \n",
            " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
            " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
            " |      \n",
            " |      Please see `tf.keras.models.save_model` or the\n",
            " |      [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n",
            " |      for details.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
            " |              model.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          include_optimizer: If True, save optimizer's state together.\n",
            " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
            " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
            " |              and 'h5' in TF 1.X.\n",
            " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
            " |              'tf' format only. Please see the `signatures` argument in\n",
            " |              `tf.saved_model.save` for details.\n",
            " |          options: (only applies to SavedModel format)\n",
            " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
            " |              saving to SavedModel.\n",
            " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
            " |              SavedModel will store the function traces for each layer. This\n",
            " |              can be disabled, so that only the configs of each layer are stored.\n",
            " |              Defaults to `True`. Disabling this will decrease serialization time\n",
            " |              and reduce file size, but it requires that all custom layers/models\n",
            " |              implement a `get_config()` method.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      from keras.models import load_model\n",
            " |      \n",
            " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
            " |      del model  # deletes the existing model\n",
            " |      \n",
            " |      # returns a compiled model\n",
            " |      # identical to the previous one\n",
            " |      model = load_model('my_model.h5')\n",
            " |      ```\n",
            " |  \n",
            " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
            " |      Saves all layer weights.\n",
            " |      \n",
            " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
            " |      argument.\n",
            " |      \n",
            " |      When saving in HDF5 format, the weight file has:\n",
            " |        - `layer_names` (attribute), a list of strings\n",
            " |            (ordered names of model layers).\n",
            " |        - For every layer, a `group` named `layer.name`\n",
            " |            - For every such layer group, a group attribute `weight_names`,\n",
            " |                a list of strings\n",
            " |                (ordered names of weights tensor of the layer).\n",
            " |            - For every weight in the layer, a dataset\n",
            " |                storing the weight value, named after the weight tensor.\n",
            " |      \n",
            " |      When saving in TensorFlow format, all objects referenced by the network are\n",
            " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
            " |      instances or `Optimizer` instances assigned to object attributes. For\n",
            " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
            " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
            " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
            " |      `Layer` instances must be assigned to object attributes, typically in the\n",
            " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
            " |      `tf.keras.Model` for details.\n",
            " |      \n",
            " |      While the formats are the same, do not mix `save_weights` and\n",
            " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
            " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
            " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
            " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
            " |      `save_weights` for training checkpoints.\n",
            " |      \n",
            " |      The TensorFlow format matches objects and variables by starting at a root\n",
            " |      object, `self` for `save_weights`, and greedily matching attribute\n",
            " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
            " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
            " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
            " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
            " |      the `Model`'s variables. See the [guide to training\n",
            " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
            " |      on the TensorFlow format.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          filepath: String or PathLike, path to the file to save the weights to.\n",
            " |              When saving in TensorFlow format, this is the prefix used for\n",
            " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
            " |              suffix causes weights to be saved in HDF5 format.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
            " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
            " |              `None` defaults to 'tf'.\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for saving weights.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
            " |              format.\n",
            " |          ValueError: For invalid/unknown format arguments.\n",
            " |  \n",
            " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
            " |      Prints a string summary of the network.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          line_length: Total length of printed lines\n",
            " |              (e.g. set this to adapt the display to different\n",
            " |              terminal window sizes).\n",
            " |          positions: Relative or absolute positions of log elements\n",
            " |              in each line. If not provided,\n",
            " |              defaults to `[.33, .55, .67, 1.]`.\n",
            " |          print_fn: Print function to use. Defaults to `print`.\n",
            " |              It will be called on each line of the summary.\n",
            " |              You can set it to a custom function\n",
            " |              in order to capture the string summary.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if `summary()` is called before the model is built.\n",
            " |  \n",
            " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Test the model on a single batch of samples.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors, if\n",
            " |            the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
            " |          ValueError: In case of invalid user-provided arguments.\n",
            " |  \n",
            " |  test_step(self, data)\n",
            " |      The logic for one evaluation step.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.make_test_function`.\n",
            " |      \n",
            " |      This function should contain the mathematical logic for one step of\n",
            " |      evaluation.\n",
            " |      This typically includes the forward pass, loss calculation, and metrics\n",
            " |      updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_test_function`, which can also be overridden.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned.\n",
            " |  \n",
            " |  to_json(self, **kwargs)\n",
            " |      Returns a JSON string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a JSON save file, use\n",
            " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `json.dumps()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON string.\n",
            " |  \n",
            " |  to_yaml(self, **kwargs)\n",
            " |      Returns a yaml string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a yaml save file, use\n",
            " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
            " |      \n",
            " |      `custom_objects` should be a dictionary mapping\n",
            " |      the names of custom losses / layers / etc to the corresponding\n",
            " |      functions / classes.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `yaml.dump()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A YAML string.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: if yaml module is not found.\n",
            " |  \n",
            " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Runs a single gradient update on a single batch of data.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |                if the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
            " |            weight (float) to apply to the model's loss for the samples from this\n",
            " |            class during training. This can be useful to tell the model to \"pay\n",
            " |            more attention\" to samples from an under-represented class.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar training loss\n",
            " |          (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
            " |        ValueError: In case of invalid user-provided arguments.\n",
            " |  \n",
            " |  train_step(self, data)\n",
            " |      The logic for one training step.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      This method is called by `Model.make_train_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of training.\n",
            " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
            " |      and metric updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_train_function`, which can also be overridden.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from tensorflow.python.keras.engine.training.Model:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
            " |  \n",
            " |  distribute_strategy\n",
            " |      The `tf.distribute.Strategy` this model was created under.\n",
            " |  \n",
            " |  metrics\n",
            " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
            " |      \n",
            " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
            " |      has been trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.add_metric(\n",
            " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc', 'mean']\n",
            " |  \n",
            " |  metrics_names\n",
            " |      Returns the model's display labels for all outputs.\n",
            " |      \n",
            " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
            " |      trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> model.metrics_names\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc']\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are expected\n",
            " |      to be updated manually in `call()`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  run_eagerly\n",
            " |      Settable attribute indicating whether the model should run eagerly.\n",
            " |      \n",
            " |      Running eagerly means that your model will be run step by step,\n",
            " |      like Python code. Your model might run slower, but it should become easier\n",
            " |      for you to debug it by stepping into individual layer calls.\n",
            " |      \n",
            " |      By default, we will attempt to compile your model to a static graph to\n",
            " |      deliver the best execution performance.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Boolean, whether the model should run eagerly.\n",
            " |  \n",
            " |  state_updates\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Returns the `updates` from all layers that are stateful.\n",
            " |      \n",
            " |      This is useful for separating training updates and\n",
            " |      state updates, e.g. when we need to update a layer's internal state\n",
            " |      during prediction.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of update ops.\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |      Wraps `call`, applying pre- and post-processing steps.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        *args: Positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |      \n",
            " |      Note:\n",
            " |        - The following optional keyword arguments are reserved for specific uses:\n",
            " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          * `mask`: Boolean input mask.\n",
            " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            " |          layers do), its default value will be set to the mask generated\n",
            " |          for `inputs` by the previous layer (if `input` did come from\n",
            " |          a layer that generated a corresponding mask, i.e. if it came from\n",
            " |          a Keras layer with masking support.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, **kwargs)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be dependent\n",
            " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(self, inputs):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any loss Tensors passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      losses become part of the model's topology and are tracked in `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss references\n",
            " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            " |      topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      d = tf.keras.layers.Dense(10)\n",
            " |      x = d(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      Arguments:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            " |          may also be zero-argument callables which create a loss tensor.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |            inputs - Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_metric(self, value, name=None, **kwargs)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      This method can be used inside the `call()` method of a subclassed layer\n",
            " |      or model.\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            " |        def __init__(self):\n",
            " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          self.add_metric(self.mean(x))\n",
            " |          self.add_metric(tf.reduce_sum(x), name='metric_2')\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any tensor passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      metrics become part of the model's topology and are tracked when you\n",
            " |      save the model via `save()`.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            " |      Functional Model, as shown in the example below, is not supported. This is\n",
            " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        name: String metric name.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |          `aggregation` - When the `value` tensor provided is not the result of\n",
            " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
            " |          using a `keras.Metric.Mean`.\n",
            " |  \n",
            " |  add_update(self, updates, inputs=None)\n",
            " |      Add update op(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and variance\n",
            " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            " |      when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case, variable\n",
            " |      updates are run on the fly and thus do not need to be tracked for later\n",
            " |      execution).\n",
            " |      \n",
            " |      Arguments:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |        inputs: Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        use_resource: Whether to use `ResourceVariable`.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses\n",
            " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            " |          `trainable` must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The variable created.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            " |  \n",
            " |  apply(self, inputs, *args, **kwargs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      This is an alias of `self.__call__`.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: Input tensor(s).\n",
            " |        *args: additional positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            " |          how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_losses_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves losses relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of loss tensors of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_updates_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves updates relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of update ops of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from Numpy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a Dense layer returns a list of two values-- per-output\n",
            " |      weights and the bias value. These can be used to set the weights of another\n",
            " |      Dense layer:\n",
            " |      \n",
            " |      >>> a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> b.set_weights(a.get_weights())\n",
            " |      >>> b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Arguments:\n",
            " |          weights: a list of Numpy arrays. The number\n",
            " |              of arrays and their shape must match\n",
            " |              number of the dimensions of the weights\n",
            " |              of the layer (i.e. it should match the\n",
            " |              output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: If the provided weights list does not match the\n",
            " |              layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the layer's computations.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
            " |      the weights.\n",
            " |      \n",
            " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
            " |      computations and the output to be in the compute dtype as well. This is done\n",
            " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
            " |      these casts if implementing your own layer.\n",
            " |      \n",
            " |      Layers often perform certain internal computations in higher precision when\n",
            " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
            " |      will still typically be float16 or bfloat16 in such cases.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The layer's compute dtype.\n",
            " |  \n",
            " |  dtype\n",
            " |      The dtype of the layer weights.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
            " |      dtype of the layer's computations.\n",
            " |  \n",
            " |  dtype_policy\n",
            " |      The dtype policy associated with this layer.\n",
            " |      \n",
            " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  losses\n",
            " |      List of losses added using the `add_loss()` API.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is accessed,\n",
            " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            " |      propagate gradients back to the corresponding variables.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            " |      ...   def call(self, inputs):\n",
            " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |      ...     return inputs\n",
            " |      >>> l = MyLayer()\n",
            " |      >>> l(np.ones((10, 1)))\n",
            " |      >>> l.losses\n",
            " |      [1.0]\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Activity regularization.\n",
            " |      >>> len(model.losses)\n",
            " |      0\n",
            " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      >>> len(model.losses)\n",
            " |      1\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            " |      >>> x = d(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Weight regularization.\n",
            " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      >>> model.losses\n",
            " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un8PDMcWQ_UZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QovEYnB4Q_Yg"
      },
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics  import confusion_matrix\n",
        "import matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4AYuCqMQ_am",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "d4c139bd-8ef7-4712-b00e-63810e576dd7"
      },
      "source": [
        "mat=confusion_matrix(y_test,y_pred)\n",
        "fig,ax=plot_confusion_matrix(conf_mat=mat,figsize=(8,8), show_normed=Fals,labe)\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWEJRv5MQ_c9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWiAiXdrX_j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}